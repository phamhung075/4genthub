planning_methodology:
  objective: |
    To create comprehensive test plans that describe every test that will be written or modified.
    Include specific test files, test cases, and verification methods.
    Define how test execution will be orchestrated across different test levels.
    
  importance: |
    A flawed test plan results in inadequate coverage and undetected bugs.
    Test plans are easier to review than actual test implementations.
    Human review of test plans ensures critical scenarios aren't missed.
    Early identification of testing gaps prevents production issues.
    
  method:
    description: Create detailed test plans with multi-level coverage strategy
    approach:
      - analyze_requirements: Understand what needs testing
      - identify_test_types: Determine unit/integration/e2e needs
      - define_test_cases: Specify exact test scenarios
      - plan_test_data: Define fixtures and mocks needed
      - orchestrate_execution: Sequence test runs properly
      
  output_specification:
    test_plan_structure:
      overview:
        - objective: What the test suite will validate
        - scope: Boundaries of testing coverage
        - test_strategy: Overall approach to testing
        - success_criteria: Definition of passing test suite
        
      test_inventory:
        description: All test files to be created or modified
        format:
          - file_path: Path to test file
          - test_type: unit|integration|e2e|performance|security
          - target_code: What code is being tested
          - action: create|modify|delete
          - test_framework: jest|mocha|pytest|etc
          
      test_cases:
        description: Specific test scenarios
        format:
          - test_id: Unique identifier
          - test_name: Descriptive test name
          - test_file: Which file contains this test
          - description: What is being tested
          - preconditions: Setup required
          - test_steps: Steps to execute
          - expected_result: What should happen
          - test_data: Required fixtures/mocks
          - priority: critical|high|medium|low
          
      test_data_management:
        description: Fixtures, mocks, and test data
        format:
          - data_type: fixture|mock|stub|spy
          - name: Identifier for the data
          - purpose: Why this data is needed
          - location: Where it will be stored
          - content: Actual data or generator
          
      coverage_strategy:
        description: How to achieve comprehensive coverage
        format:
          - coverage_type: line|branch|function|statement
          - target_percentage: Desired coverage level
          - critical_paths: Must-test code paths
          - exclusions: What won't be tested and why
          
      execution_orchestration:
        description: How tests will be run
        format:
          - execution_phase: Phase identifier
          - test_suites: Which suites run in this phase
          - parallelization: Can tests run in parallel
          - dependencies: Tests that must run first
          - environment: Required test environment
          - cleanup: Post-test cleanup needed
          
      test_delegation:
        description: Assignment to specialized test agents
        format:
          - test_type: Type of testing
          - assigned_agent: Agent responsible
          - specific_tests: Tests they will handle
          - coordination: How they interact with others
          
  quality_standards:
    - completeness: All code paths have test coverage
    - isolation: Tests are independent and repeatable
    - clarity: Test names clearly describe what's tested
    - maintainability: Tests are easy to update
    - performance: Tests run efficiently
    - determinism: Tests produce consistent results
    
  test_patterns:
    AAA_pattern:
      description: Arrange-Act-Assert pattern
      structure:
        - arrange: Set up test data and conditions
        - act: Execute the code being tested
        - assert: Verify the results
        
    given_when_then:
      description: BDD style test structure
      structure:
        - given: Initial context
        - when: Action occurs
        - then: Expected outcome
        
    test_pyramid:
      description: Balanced test distribution
      distribution:
        - unit: 70% - Fast, isolated tests
        - integration: 20% - Component interaction tests
        - e2e: 10% - Full system tests
        
  validation_checklist:
    before_execution:
      - test_environment: Environment properly configured
      - test_data: All fixtures and mocks ready
      - dependencies: Required services available
      - isolation: Tests won't interfere with each other
      
    during_execution:
      - progress_monitoring: Track test completion
      - failure_tracking: Log failing tests
      - performance_metrics: Monitor test duration
      - resource_usage: Check memory/CPU usage
      
    after_execution:
      - coverage_report: Generate coverage metrics
      - failure_analysis: Investigate failures
      - performance_review: Identify slow tests
      - cleanup_verification: Ensure proper cleanup
      
  example_test_plan:
    overview:
      objective: "Comprehensive testing of authentication system"
      scope: "JWT service, middleware, and API endpoints"
      test_strategy: "Bottom-up testing from units to integration"
      success_criteria: "100% pass rate, >90% coverage"
      
    test_inventory:
      - file_path: "tests/unit/jwt.service.test.ts"
        test_type: "unit"
        target_code: "src/auth/jwt.service.ts"
        action: "create"
        test_framework: "jest"
        
      - file_path: "tests/integration/auth.middleware.test.ts"
        test_type: "integration"
        target_code: "src/middleware/auth.middleware.ts"
        action: "create"
        test_framework: "jest"
        
      - file_path: "tests/e2e/auth.flow.test.ts"
        test_type: "e2e"
        target_code: "Complete authentication flow"
        action: "create"
        test_framework: "playwright"
        
    test_cases:
      - test_id: "TC-001"
        test_name: "should generate valid JWT token"
        test_file: "tests/unit/jwt.service.test.ts"
        description: "Verify JWT token generation with correct claims"
        test_steps:
          - "Create JWTService instance"
          - "Call generateToken with userId"
          - "Decode token and verify claims"
        expected_result: "Valid JWT with userId and expiry"
        test_data: "Mock userId: 'user123'"
        priority: "critical"
        
      - test_id: "TC-002"
        test_name: "should reject invalid token"
        test_file: "tests/unit/jwt.service.test.ts"
        description: "Verify invalid tokens are rejected"
        test_steps:
          - "Create JWTService instance"
          - "Provide malformed token"
          - "Call verifyToken"
        expected_result: "Throws InvalidTokenError"
        test_data: "Invalid token: 'bad.token.here'"
        priority: "critical"
        
      - test_id: "TC-003"
        test_name: "middleware blocks unauthenticated requests"
        test_file: "tests/integration/auth.middleware.test.ts"
        description: "Verify middleware protects routes"
        test_steps:
          - "Setup Express app with middleware"
          - "Make request without token"
          - "Check response"
        expected_result: "401 Unauthorized response"
        priority: "high"
        
    test_data_management:
      - data_type: "fixture"
        name: "validUserData"
        purpose: "Standard user for testing"
        location: "tests/fixtures/users.json"
        content: |
          {
            "id": "user123",
            "email": "test@example.com",
            "role": "user"
          }
          
      - data_type: "mock"
        name: "jwtServiceMock"
        purpose: "Mock JWT service for middleware tests"
        location: "tests/mocks/jwt.service.mock.ts"
        content: |
          export const jwtServiceMock = {
            generateToken: jest.fn(),
            verifyToken: jest.fn()
          };
          
    coverage_strategy:
      coverage_type: "branch"
      target_percentage: 90
      critical_paths:
        - "Token generation logic"
        - "Token verification logic"
        - "Error handling paths"
      exclusions:
        - "src/config/*: Configuration files"
        - "src/types/*: Type definitions"
        
    execution_orchestration:
      - execution_phase: "Unit Tests"
        test_suites: ["jwt.service.test.ts", "auth.utils.test.ts"]
        parallelization: true
        environment: "Node.js test environment"
        
      - execution_phase: "Integration Tests"
        test_suites: ["auth.middleware.test.ts", "auth.api.test.ts"]
        parallelization: false
        dependencies: ["Unit Tests"]
        environment: "Test database required"
        cleanup: "Clear test database"
        
      - execution_phase: "E2E Tests"
        test_suites: ["auth.flow.test.ts"]
        parallelization: false
        dependencies: ["Integration Tests"]
        environment: "Full application stack"
        cleanup: "Reset all test data"
        
    test_delegation:
      - test_type: "Performance Testing"
        assigned_agent: "@performance-load-tester-agent"
        specific_tests: ["Load test auth endpoints", "Stress test token generation"]
        coordination: "Results shared with @test-orchestrator-agent"
        
      - test_type: "Security Testing"
        assigned_agent: "@security-auditor-agent"
        specific_tests: ["SQL injection tests", "Token security validation"]
        coordination: "Critical issues escalated immediately"